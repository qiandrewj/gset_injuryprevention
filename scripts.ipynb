{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Imports\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define statistical accuracy display functions\n",
    "\n",
    "def printMAPE(test_features, test_label, model):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_label)\n",
    "    print(\"Mean Absolute Error: \" np.mean(errors))\n",
    "    pct_errors = 100 * (errors / test_label)\n",
    "    print(\"Mean Absolute Percentage Error: \", np.mean(pct_errors))\n",
    "\n",
    "def printMAPE_train(train_features, train_label, model):\n",
    "    predictions = model.predict(train_features)\n",
    "    errors = abs(predictions - train_label)\n",
    "    print(\"Training Mean Absolute Error: \", np.mean(errors))\n",
    "    pct_errors = 100 * (errors / train_label)\n",
    "    print(\"Training Mean Absolute Percentage Error: \", np.mean(pct_errors))\n",
    "\n",
    "def getEnsembleTreeVars(ensTree, varNames):\n",
    "    importance = ensTree.feature_importances_\n",
    "    index = np.argsort(importance)\n",
    "    vars = []\n",
    "    for i in index:\n",
    "        imp_val = importance[i]\n",
    "        if imp_val > np.average(importance):\n",
    "            v = int(imp_val / np.max(importance) * 100)\n",
    "            vars.append(varNames[i])\n",
    "    vars = sorted(vars, key = itemgetter(1), reverse = True)\n",
    "    return vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up train-test split on dataset\n",
    "\n",
    "df = pd.read_csv(\"dataset_schools_avg.csv\")\n",
    "labels = np.array(df[\"Sparta score\"])\n",
    "features = df.drop([\"Sparta score\", \"School District\"], axis = 1)\n",
    "\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run random forest regressor with 1,000 decision trees on training data\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "printMAPE(X_test, y_test, rf)\n",
    "printMAPE_train(X_train, y_train, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_importantvars = getEnsembleTreeVars(rf, feature_list)\n",
    "print(rf_importantvars)\n",
    "\n",
    "rf_bestvars = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "labels_bestvars = np.array(df[\"Sparta score\"])\n",
    "features_bestvars = df.drop([\"Sparta score\", \"School District\", \"% White\", \"% Speaks English only\", \"% Below poverty line\", \"Median Household Income of Parents\", \"% Married-couple families\", \"% Food Stamp benefits\", \"% Health Insurance Coverage\"], axis = 1)\n",
    "\n",
    "feature_list = list(features_bestvars.columns)\n",
    "features = np.array(features_bestvars)\n",
    "\n",
    "X_train_best, X_test_best, y_train_best, y_test_best = train_test_split(features, labels, test_size = 0.2, random_state = 42)\n",
    "\n",
    "rf_bestvars = rf_bestvars.fit(X_train_best, y_train_best)\n",
    "printMAPE(X_test_best, y_test_best, rf_bestvars)\n",
    "printMAPE_train(X_train_best, y_train_best, rf_bestvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting attempt\n",
    "\n",
    "from sklearn import ensemble\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 1000,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss\": \"squared_error\",\n",
    "}\n",
    "\n",
    "gbr = ensemble.GradientBoostingRegressor(**params)\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "printMAPE(X_test, y_test, gbr)\n",
    "printMAPE_train(X_train, y_train, gbr)\n",
    "\n",
    "test_score = np.zeros((params[\"n_estimators\"]), dtype = np.float64)\n",
    "for i, y_pred in enumerate(gbr.staged_predict(X_test)):\n",
    "    test_score[i] = gbr.loss_(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "rf.get_params()\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1100, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = [\"auto\", \"sqrt\"]\n",
    "\n",
    "# Maximum tree depth\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method for selecting training samples\n",
    "bootstrap = [True, False]\n",
    "\n",
    "grid = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_features\": max_features,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_split\": min_samples_split,\n",
    "    \"min_samples_leaf\": min_samples_leaf,\n",
    "    \"bootstrap\": bootstrap\n",
    "}\n",
    "\n",
    "grid_gbr = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_features\": max_features,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_split\": min_samples_split,\n",
    "    \"min_samples_leaf\": min_samples_leaf,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "# Tuning model 1\n",
    "rf_grid = RandomizedSearchCV(estimator = rf, param_grid = grid, n_jobs = -1, cv = 2, verbose = 2)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_grid.best_estimator_.get_params()\n",
    "\n",
    "rf_grid = GridSearchCV(estimator = rf, param_grid = grid, n_jobs = -1, cv = 2, verbose = 2)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_grid.best_estimator_.get_params()\n",
    "\n",
    "# Tuning model 2\n",
    "rf_grid_best = RandomizedSearchCV(estimator = rf_bestvars, param_grid = grid, n_jobs = -1, cv = 2, verbose = 2)\n",
    "rf_grid_best.fit(X_train_best, y_train_best)\n",
    "rf_grid_best.best_estimator_.get_params()\n",
    "\n",
    "rf_grid_best = GridSearchCV(estimator = rf_bestvars, param_grid = grid, n_jobs = -1, cv = 2, verbose = 2)\n",
    "rf_grid.fit(X_train_best, y_train_best)\n",
    "rf_grid_best.best_estimator_.get_params()\n",
    "\n",
    "gbr_grid = GridSearchCV(estimator = gbr, param_grid = grid_gbr, n_jobs = -1, cv = 2, verbose = 2)\n",
    "gbr_grid.fit(X_train, y_train)\n",
    "printMAPE(X_test, y_test, gbr_grid.best_estimator_)\n",
    "printMAPE_train(X_train, y_train, gbr_grid.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
